from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_community.callbacks.manager import get_openai_callback
from langchain_core.messages import HumanMessage, SystemMessage
import os
import sys
import json
import asyncio
from dotenv import load_dotenv

# OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãŠã
# .envã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€OPENAI_API_KEY=<API KEY>ã‚’è¨˜è¼‰ã™ã‚‹
load_dotenv()

# OpenAIã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
# max_tokensã§ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³é‡ã«åˆ¶é™ã‚’ã‹ã‘ã‚‹
# max_token*100ãã‚‰ã„ãŒå®Ÿéš›ã®åˆ¶é™å€¤ï¼Ÿ
llm = ChatOpenAI(
    model_name="gpt-4.1",
    temperature=0,
    max_tokens=1000,
)

initial_messages = [
    SystemMessage(
        content=(
            "ã‚ãªãŸã¯å„ªç§€ãªã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã§ã™ã€‚"
            "create_fileã§pythonã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ãŸå¾Œã«run_python_fileã‚’å®Ÿè¡Œã™ã‚Œã°å®Ÿè£…ã—ãŸå†…å®¹ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚"
            "æ—¥ä»˜ç­‰ã®æœ€æ–°æƒ…å ±ã¯pythonã§è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        )
    ),  
]

client = MultiServerMCPClient(
    {
        "FileIO": {
            "command": "python",
            "args": ["/app/file_io_mcp.py"],
            "transport": "stdio",
        },
        "ExecutePythonByFilename": {
            "command": "python",
            "args": ["/app/exec_py_mcp.py"],
            "transport": "stdio",
        },
    }
)


async def agent_invoke(agent, messages):
    response = None

    with get_openai_callback() as cb:
        response = await agent.ainvoke(
            {"messages": messages}
        )

        for msg in response["messages"]:
            msg.pretty_print()

        print(f"ğŸ”¢ ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {cb.total_tokens}")
        print(f"ğŸ“¥ å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {cb.prompt_tokens}")
        print(f"ğŸ“¤ å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {cb.completion_tokens}")
        print(f"ğŸ’° æ¨å®šã‚³ã‚¹ãƒˆ: ${cb.total_cost:.6f}")
    
    return response

async def main():
    tools = await client.get_tools()
    agent = create_react_agent(
        llm,
        tools,
    )

    messages = initial_messages
    print("ğŸ” å…¥åŠ›ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ï¼ˆ'exit', 'quit', ç©ºå…¥åŠ›ã§çµ‚äº†ï¼‰")

    while True:
        old_messages = messages.copy()
        user_input = input("user>>> ").strip()
        if user_input in ("exit", "quit", ""):
            print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™")
            break
        try:
            human_message = HumanMessage(content=user_input)
            messages.append(human_message)

            result_response = await agent_invoke(agent, messages)
            messages = result_response["messages"]
        except Exception as e:
            print(f"[âœ—] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            messages = old_messages

if __name__ == "__main__":
    asyncio.run(main())

