from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_community.callbacks.manager import get_openai_callback
from langchain_core.messages import HumanMessage, SystemMessage
import os
import json
import asyncio
from dotenv import load_dotenv

# OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãŠã
# .envã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€OPENAI_API_KEY=<API KEY>ã‚’è¨˜è¼‰ã™ã‚‹
load_dotenv()

# OpenAIã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
llm = ChatOpenAI(
    model_name="gpt-4.1",
    temperature=0,
)

client = MultiServerMCPClient(
    {
        "Weather": {
            "command": "python",
            "args": ["/app/weather_mcp.py"],
            "transport": "stdio",
        },
        "RoomStatusNow": {
            "command": "python",
            "args": ["/app/room_mcp.py"],
            "transport": "stdio",
        },
    }
)

async def main():
    response = None
    tools = await client.get_tools()
    agent = create_react_agent(
        llm,
        tools,
    )

    messages = [
        SystemMessage(
            content=(
                "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ã§ã™ã€‚"
                "éŸ³å£°èª­ã¿ä¸Šã’ã—ã‚„ã™ã„ã‚ˆã†ãª150å­—ç¨‹åº¦ã®æ–‡ç« ã«ã—ã¦ãã ã•ã„ã€‚"
            )            
        ),
        HumanMessage(
            content=(
                "æ˜æ—¥ã®å¤©æ°—ã¨ãŠã™ã™ã‚ã®æœè£…ã¯ï¼Ÿ"
            )
        )
    ]

    with get_openai_callback() as cb:
        response = await agent.ainvoke(
            {"messages": messages}
        )

        for msg in response["messages"]:
            msg.pretty_print()

        print(f"ğŸ”¢ ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {cb.total_tokens}")
        print(f"ğŸ“¥ å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {cb.prompt_tokens}")
        print(f"ğŸ“¤ å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {cb.completion_tokens}")
        print(f"ğŸ’° æ¨å®šã‚³ã‚¹ãƒˆ: ${cb.total_cost:.6f}")
    
    return response


if __name__ == "__main__":
    resp = asyncio.run(main())

